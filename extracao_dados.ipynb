{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d003d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install datasets\n",
    "#!pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b407b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09feab67",
   "metadata": {},
   "source": [
    "### Extração do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d726caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36897, 6)\n",
      "(1000, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# extrair o dataset\n",
    "df = pd.read_parquet(\"hf://datasets/manoh2f2/tsterbak-lyrics-dataset-with-emotions/data/train-00000-of-00001.parquet\")\n",
    "print(df.shape)\n",
    "\n",
    "# shuffle dos dados e reseta também o indice\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# redução do dataset\n",
    "df = df.iloc[0:1000, :]\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "#tratamento do problema das letras ter este _x000D_ caracter especial\n",
    "df['seq'] = df['seq'].str.replace(\"_x000D_\", \"\", regex=False)\n",
    "\n",
    "\n",
    "# print(df)\n",
    "\n",
    "#x = df.iloc[2]['seq']\n",
    "#print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ab8d6f",
   "metadata": {},
   "source": [
    "### Query do SPARQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a12d14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Total de artistas únicos: 642\n"
     ]
    }
   ],
   "source": [
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "cache_file = \"genre_cache.json\"\n",
    "# cache_str_keys é do tipo { \"song||artist\": genre }\n",
    "if os.path.exists(cache_file):\n",
    "    with open(cache_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        cache_str_keys = json.load(f)\n",
    "        print(len(cache_str_keys))\n",
    "else:\n",
    "    cache_str_keys = {}\n",
    "    with open(cache_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cache_str_keys, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "def count_unique_artists(cache_file):\n",
    "    with open(cache_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # extrai o artista da chave \"song||artist\"\n",
    "    artists = [key.split(\"||\")[1] for key in data.keys()]\n",
    "    unique_artists = set(artists)\n",
    "    \n",
    "    print(f\"Total de artistas únicos: {len(unique_artists)}\")\n",
    "    return unique_artists\n",
    "\n",
    "\n",
    "def get_genre2(artist_name):\n",
    "    query = f\"\"\"\n",
    "    SELECT ?genreLabel WHERE {{\n",
    "      ?artist rdfs:label \"{artist_name}\"@en;\n",
    "              wdt:P136 ?genre.\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    if results[\"results\"][\"bindings\"]:\n",
    "        return results[\"results\"][\"bindings\"][0][\"genreLabel\"][\"value\"]\n",
    "\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "\n",
    "def get_genre(song_name,artist_name):\n",
    "    \n",
    "    song_name = song_name.replace('\"', '').replace(\"'\", '')\n",
    "    artist_name = artist_name.replace('\"', '').replace(\"'\", '')\n",
    "    query = f\"\"\"\n",
    "    SELECT ?genreLabel WHERE {{\n",
    "      ?artist rdfs:label \"{song_name}\"@en;\n",
    "            wdt:P31 wd:Q7366;          # garante que é uma canção\n",
    "            wdt:P136 ?genre.\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "\n",
    "    if results[\"results\"][\"bindings\"]:\n",
    "        return results[\"results\"][\"bindings\"][0][\"genreLabel\"][\"value\"]\n",
    "\n",
    "    else:\n",
    "        return get_genre2(artist_name) # Caso não encontre género para a música em especifico, vai buscar o género do artista\n",
    "\n",
    "\n",
    "\n",
    "def get_genre_cached(song_name, artist_name):\n",
    "    key = f\"{song_name}||{artist_name}\"  # chave como string\n",
    "    if key in cache_str_keys:\n",
    "        return cache_str_keys[key]\n",
    "    \n",
    "    genre = get_genre(song_name, artist_name)  # faz SPARQL se não estiver\n",
    "    cache_str_keys[key] = genre\n",
    "\n",
    "    # salva a cache imediatamente no JSON\n",
    "    with open(\"genre_cache.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cache_str_keys, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return genre\n",
    "\n",
    "\n",
    "\n",
    "# artist = df.iloc[2][\"artist\"]\n",
    "# song = df.iloc[2][\"song\"]\n",
    "# genre = get_genre(song,artist)\n",
    "\n",
    "# print(f\"Artista: {artist}\")\n",
    "# print(f\"Género: {genre}\")\n",
    "\n",
    "#df[\"genre\"] = df[\"artist\"].apply(get_genre)\n",
    "\n",
    "\n",
    "count_unique_artists(cache_file)\n",
    "df[\"genre\"] = [get_genre_cached(title, artist) for title, artist in zip(df[\"song\"], df[\"artist\"])]\n",
    "\n",
    "\n",
    "df.to_csv(\"lyrics_with_genre.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a6f4b",
   "metadata": {},
   "source": [
    "### Gráfico de conhecimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c488628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, Namespace, Literal, RDF, URIRef\n",
    "from pyvis.network import Network\n",
    "\n",
    "#with open(\"genre_cache.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#    data = json.load(f)\n",
    "\n",
    "data = {\n",
    "  \"I Was Born About Ten Thousand Years Ago||Elvis Presley\": \"rock and roll\",\n",
    "  \"Citadel||The Damned\": \"drama film\",\n",
    "  \"Down the Drain||Down by Law\": \"drama film\",\n",
    "  \"Hymn||Patti Smith\": \"Unknown\",\n",
    "  \"Candy||LL Cool J\": \"pop music\",\n",
    "  \"Little Birds||Dead to Fall\": \"indie rock\",\n",
    "  \"Hannah||Sheila Nicholls\": \"Unknown\",\n",
    "  \"Mental Slavery||Kreator\": \"thrash metal\",\n",
    "  \"Playin' Dominoes and Shootin' Dice||Willie Nelson\": \"blues\"\n",
    "}\n",
    "\n",
    "def knowledgeGragh(data):\n",
    "    # Criar o grafo\n",
    "    g = Graph()\n",
    "\n",
    "    EX = Namespace(\"http://example.org/\")\n",
    "    g.bind(\"\", EX)\n",
    "\n",
    "    # Criar classes\n",
    "    g.add((EX.Music, RDF.type, EX.Class))\n",
    "    g.add((EX.Artist, RDF.type, EX.Class))\n",
    "    g.add((EX.Genre, RDF.type, EX.Class))\n",
    "\n",
    "    # Criar propriedades\n",
    "    g.add((EX.hasArtist, RDF.type, EX.Property))\n",
    "    g.add((EX.hasGenre, RDF.type, EX.Property))\n",
    "\n",
    "    # --------- ADICIONAR INDIVÍDUOS ---------\n",
    "    for key, genre in data.items():\n",
    "        title, artist = key.split(\"||\")\n",
    "\n",
    "        # Criar URIs \"limpos\"\n",
    "        title_uri = EX[title.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"\\\"\", \"\").replace(\"'\", \"_\")]\n",
    "        artist_uri = EX[artist.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"\\\"\", \"\")]\n",
    "        genre_uri = EX[genre.replace(\" \", \"_\").replace(\"/\", \"_\")]\n",
    "\n",
    "        # Música é indivíduo da classe Music\n",
    "        g.add((title_uri, RDF.type, EX.Music))\n",
    "\n",
    "        # Artista é indivíduo da classe Artist\n",
    "        g.add((artist_uri, RDF.type, EX.Artist))\n",
    "\n",
    "        # Género é indivíduo da classe Genre\n",
    "        g.add((genre_uri, RDF.type, EX.Genre))\n",
    "\n",
    "        # Relacionar a música com artista e género\n",
    "        g.add((title_uri, EX.hasArtist, artist_uri))\n",
    "        g.add((title_uri, EX.hasGenre, genre_uri))\n",
    "\n",
    "    g.serialize(\"musicas.ttl\", format=\"turtle\")\n",
    "\n",
    "    # Carregar o teu grafo RDFLib\n",
    "    g = Graph()\n",
    "    g.parse(\"musicas.ttl\", format=\"turtle\")\n",
    "\n",
    "    # --- preparar visualização PyVis com processamento mais limpo ---\n",
    "    net = Network(height=\"750px\", width=\"100%\", directed=True)\n",
    "    net.barnes_hut()  # layout melhor para grafos maiores\n",
    "\n",
    "    # iremos recolher tipos (Music / Artist / Genre) e depois construir nós/arestas sem triples rdf:type visíveis\n",
    "    class_uris = {EX.Music, EX.Artist, EX.Genre}\n",
    "    node_type = {}   # mapa: URI -> 'Music'|'Artist'|'Genre'|'Other'\n",
    "\n",
    "    # primeiro passar pelos triples para identificar rdf:type de instâncias\n",
    "    for s, p, o in g:\n",
    "        if p == RDF.type and o in class_uris:\n",
    "            # marca o tipo da instância (s é a instância, o é a classe)\n",
    "            if o == EX.Music:\n",
    "                node_type[s] = \"Music\"\n",
    "            elif o == EX.Artist:\n",
    "                node_type[s] = \"Artist\"\n",
    "            elif o == EX.Genre:\n",
    "                node_type[s] = \"Genre\"\n",
    "\n",
    "    # depois criar nós e arestas (ignorando triples que apenas declaram as classes em si)\n",
    "    seen_nodes = set()\n",
    "\n",
    "    def label(uri):\n",
    "        \"\"\"Gera label legível: tenta qname, fallback para o último segmento do URIRef\"\"\"\n",
    "        try:\n",
    "            return g.qname(uri)\n",
    "        except Exception:\n",
    "            s = str(uri)\n",
    "            return s.split(\"/\")[-1].split(\"#\")[-1]\n",
    "\n",
    "    # cores/grupos para PyVis (o \"group\" facilita legenda/estética)\n",
    "    group_map = {\n",
    "        \"Music\": \"music\",\n",
    "        \"Artist\": \"artist\",\n",
    "        \"Genre\": \"genre\"\n",
    "    }\n",
    "\n",
    "    # Adicionar nós e arestas: para cada triple, se for rdf:type (instância->classe) já processado -> ignorar visualmente.\n",
    "    for s, p, o in g:\n",
    "        # Só mostrar indivíduos, não classes\n",
    "        if o in (EX.Music, EX.Artist, EX.Genre):\n",
    "            continue\n",
    "        # ignorar declarações do próprio esquema (ex.: EX.Music rdf:type EX.Class) e rdf:type ligações já processadas\n",
    "        if s in {EX.Music, EX.Artist, EX.Genre}:\n",
    "            continue\n",
    "        if p == RDF.type and o in class_uris:\n",
    "            # Não criar aresta rdf:type visível — apenas asseguramos node_type acima\n",
    "            continue\n",
    "\n",
    "        # garantir nós s e o com labels legíveis\n",
    "        if s not in seen_nodes:\n",
    "            lbl = label(s)\n",
    "            grp = group_map.get(node_type.get(s, \"Other\"), \"other\")\n",
    "            net.add_node(str(s), label=lbl, title=str(s), group=grp)\n",
    "            seen_nodes.add(s)\n",
    "        if o not in seen_nodes:\n",
    "            lbl = label(o)\n",
    "            grp = group_map.get(node_type.get(o, \"Other\"), \"other\")\n",
    "            net.add_node(str(o), label=lbl, title=str(o), group=grp)\n",
    "            seen_nodes.add(o)\n",
    "\n",
    "        # adicionar aresta com rótulo do predicado (localname)\n",
    "        pred_label = label(p)\n",
    "        net.add_edge(str(s), str(o), label=pred_label, title=pred_label)\n",
    "\n",
    "knowledgeGragh(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
